name: 'Create Requirements Task CI/CD Pipeline'

# è§¸ç™¼æ¢ä»¶
on:
  push:
    branches: [ main, develop ]
    paths:
      - 'general/tasks/create-requirements.md'
      - 'general/templates/**'
      - 'ci-cd/create-requirements/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'general/tasks/create-requirements.md' 
      - 'general/templates/**'
      - 'ci-cd/create-requirements/**'
  workflow_dispatch:  # å…è¨±æ‰‹å‹•è§¸ç™¼
    inputs:
      environment:
        description: 'æ¸¬è©¦ç’°å¢ƒé¸æ“‡'
        required: true
        default: 'test'
        type: choice
        options:
          - dev
          - test
          - prod
      skip_quality_gate:
        description: 'è·³éå“è³ªé–€æª»æª¢æŸ¥'
        required: false
        default: false
        type: boolean

# ç’°å¢ƒè®Šæ•¸
env:
  NODE_VERSION: '18'
  WORKING_DIR: 'ci-cd/create-requirements'

# å·¥ä½œæµç¨‹
jobs:
  # éšæ®µ1ï¼šé è™•ç†é©—è­‰
  pre-validation:
    name: 'ğŸ“‹ é è™•ç†é©—è­‰'
    runs-on: ubuntu-latest
    outputs:
      validation-passed: ${{ steps.validation.outputs.passed }}
      files-changed: ${{ steps.changes.outputs.files }}
    
    steps:
      - name: 'ğŸ“¥ Checkoutä»£ç¢¼'
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # éœ€è¦æ¯”è¼ƒè®Šæ›´
      
      - name: 'ğŸ“‚ æª¢æŸ¥æ–‡ä»¶è®Šæ›´'
        id: changes
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            changed_files=$(git diff --name-only HEAD^ HEAD)
          else
            changed_files=$(git diff --name-only HEAD~1 HEAD)
          fi
          echo "files<<EOF" >> $GITHUB_OUTPUT
          echo "$changed_files" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "Changed files: $changed_files"
      
      - name: 'ğŸ” YAMLèªæ³•æª¢æŸ¥'
        run: |
          # å®‰è£yamllint
          pip install yamllint
          
          # æª¢æŸ¥æ‰€æœ‰YAMLé…ç½®æ–‡ä»¶
          echo "æª¢æŸ¥promptfooé…ç½®æ–‡ä»¶..."
          if [ -f "$WORKING_DIR/promptfoo.config.js" ]; then
            echo "âœ… Promptfooé…ç½®æ–‡ä»¶å­˜åœ¨"
          else
            echo "âŒ Promptfooé…ç½®æ–‡ä»¶ä¸å­˜åœ¨"
            exit 1
          fi
          
          # æª¢æŸ¥æ¸¬è©¦é…ç½®YAMLæ–‡ä»¶
          yaml_files=$(find $WORKING_DIR/tests -name "*.yml" 2>/dev/null || echo "")
          if [ -n "$yaml_files" ]; then
            echo "æª¢æŸ¥æ¸¬è©¦é…ç½®æ–‡ä»¶ï¼š"
            echo "$yaml_files" | xargs yamllint -d relaxed
            echo "âœ… YAMLæ–‡ä»¶èªæ³•æª¢æŸ¥é€šé"
          else
            echo "âš ï¸  æœªæ‰¾åˆ°YAMLæ¸¬è©¦é…ç½®æ–‡ä»¶"
          fi
      
      - name: 'ğŸ“‹ Markdownæ ¼å¼é©—è­‰'
        run: |
          # æª¢æŸ¥éœ€æ±‚taskæ–‡ä»¶
          if [ -f "general/tasks/create-requirements.md" ]; then
            echo "âœ… Create Requirementsä»»å‹™æ–‡ä»¶å­˜åœ¨"
            
            # ç°¡å–®çš„æ ¼å¼æª¢æŸ¥
            if grep -q "<input>" "general/tasks/create-requirements.md" && \
               grep -q "<output>" "general/tasks/create-requirements.md" && \
               grep -q "<workflow>" "general/tasks/create-requirements.md"; then
              echo "âœ… ä»»å‹™æ–‡ä»¶æ ¼å¼æ­£ç¢º"
            else
              echo "âŒ ä»»å‹™æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„æ ¼å¼æ¨™ç±¤"
              exit 1
            fi
          else
            echo "âŒ Create Requirementsä»»å‹™æ–‡ä»¶ä¸å­˜åœ¨"
            exit 1
          fi
      
      - name: 'âœ… é©—è­‰çµæœ'
        id: validation
        run: |
          echo "passed=true" >> $GITHUB_OUTPUT
          echo "âœ… é è™•ç†é©—è­‰é€šé"

  # éšæ®µ2ï¼šç’°å¢ƒè¨­ç½®å’Œä¾è³´å®‰è£
  setup-environment:
    name: 'ğŸ”§ ç’°å¢ƒè¨­ç½®'
    runs-on: ubuntu-latest
    needs: pre-validation
    if: needs.pre-validation.outputs.validation-passed == 'true'
    strategy:
      matrix:
        test-env: [dev, test]  # æ”¯æ´å¤šç’°å¢ƒæ¸¬è©¦
    
    steps:
      - name: 'ğŸ“¥ Checkoutä»£ç¢¼'
        uses: actions/checkout@v4
      
      - name: 'âš™ï¸ è¨­ç½®Node.js'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: ${{ env.WORKING_DIR }}/package.json
      
      - name: 'ğŸ“¦ å®‰è£ä¾è³´'
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          # å‰µå»ºpackage.jsonå¦‚æœä¸å­˜åœ¨
          if [ ! -f package.json ]; then
            cat > package.json << EOF
          {
            "name": "create-requirements-ci",
            "version": "1.0.0",
            "description": "CI/CD for Create Requirements Task",
            "scripts": {
              "test": "promptfoo eval",
              "test:verbose": "promptfoo eval --verbose",
              "quality-gate": "node scripts/quality-gate.js"
            },
            "dependencies": {
              "@promptfoo/cli": "^0.47.0",
              "js-yaml": "^4.1.0",
              "dotenv": "^16.3.1"
            },
            "engines": {
              "node": ">=18.0.0"
            }
          }
          EOF
            echo "âœ… å‰µå»ºpackage.json"
          fi
          
          # å®‰è£ä¾è³´
          npm install
          
          # é©—è­‰promptfooå®‰è£
          npx promptfoo --version
          echo "âœ… Promptfooå®‰è£æˆåŠŸ"
      
      - name: 'ğŸ” è¼‰å…¥ç’°å¢ƒè®Šæ•¸'
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          # å‰µå»ºç’°å¢ƒç‰¹å®šçš„.envæ–‡ä»¶
          cat > .env << EOF
          # ${{ matrix.test-env }} ç’°å¢ƒé…ç½®
          NODE_ENV=${{ matrix.test-env }}
          ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}
          ANTHROPIC_BASE_URL=${{ secrets.ANTHROPIC_BASE_URL || 'https://api.anthropic.com' }}
          ANTHROPIC_MODEL=${{ secrets.ANTHROPIC_MODEL || 'claude-3-5-sonnet-20241022' }}
          
          # æ¸¬è©¦é…ç½®
          TEST_RUNS=${{ matrix.test-env == 'dev' && '2' || '3' }}
          CONSISTENCY_THRESHOLD=${{ matrix.test-env == 'dev' && '0.80' || '0.85' }}
          QUALITY_THRESHOLD=${{ matrix.test-env == 'dev' && '75' || '85' }}
          
          # å“è³ªé–¾å€¼
          AGENT_CONSISTENCY_THRESHOLD=${{ matrix.test-env == 'dev' && '80' || '90' }}
          DOC_QUALITY_THRESHOLD=${{ matrix.test-env == 'dev' && '75' || '85' }}
          TOOL_USAGE_THRESHOLD=${{ matrix.test-env == 'dev' && '90' || '95' }}
          TEMPLATE_COMPLIANCE_THRESHOLD=100
          OVERALL_SUCCESS_THRESHOLD=${{ matrix.test-env == 'dev' && '85' || '90' }}
          EOF
          
          echo "âœ… ç’°å¢ƒè®Šæ•¸é…ç½®å®Œæˆ (${{ matrix.test-env }})"
      
      - name: 'ğŸ’¾ å¿«å–ç’°å¢ƒè¨­ç½®'
        uses: actions/cache@v3
        with:
          path: |
            ${{ env.WORKING_DIR }}/node_modules
            ${{ env.WORKING_DIR }}/.env
          key: ${{ runner.os }}-create-requirements-${{ matrix.test-env }}-${{ hashFiles('**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-create-requirements-${{ matrix.test-env }}-
            ${{ runner.os }}-create-requirements-

  # éšæ®µ3ï¼šAgentä¸€è‡´æ€§æ¸¬è©¦
  agent-consistency-tests:
    name: 'ğŸ¤– Agentä¸€è‡´æ€§æ¸¬è©¦'
    runs-on: ubuntu-latest
    needs: [pre-validation, setup-environment]
    if: needs.pre-validation.outputs.validation-passed == 'true'
    strategy:
      matrix:
        test-env: [dev, test]
        test-suite: [simple, complex, edge-cases]
      fail-fast: false  # ä¸è¦å› ç‚ºä¸€å€‹æ¸¬è©¦å¤±æ•—å°±åœæ­¢æ‰€æœ‰æ¸¬è©¦
    
    steps:
      - name: 'ğŸ“¥ Checkoutä»£ç¢¼'
        uses: actions/checkout@v4
      
      - name: 'â™»ï¸ æ¢å¾©ç’°å¢ƒå¿«å–'
        uses: actions/cache@v3
        with:
          path: |
            ${{ env.WORKING_DIR }}/node_modules
            ${{ env.WORKING_DIR }}/.env
          key: ${{ runner.os }}-create-requirements-${{ matrix.test-env }}-${{ hashFiles('**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-create-requirements-${{ matrix.test-env }}-
      
      - name: 'ğŸ§ª åŸ·è¡ŒAgentä¸€è‡´æ€§æ¸¬è©¦'
        working-directory: ${{ env.WORKING_DIR }}
        timeout-minutes: 15  # è¨­ç½®è¶…æ™‚é˜²æ­¢hanging
        run: |
          echo "ğŸš€ é–‹å§‹åŸ·è¡ŒAgentä¸€è‡´æ€§æ¸¬è©¦ (${{ matrix.test-env }} - ${{ matrix.test-suite }})"
          
          # ç¢ºä¿æ¸¬è©¦çµæœç›®éŒ„å­˜åœ¨
          mkdir -p test-results
          
          # åŸ·è¡Œç‰¹å®šæ¸¬è©¦å¥—ä»¶
          if [ "${{ matrix.test-suite }}" = "simple" ]; then
            # åŸ·è¡Œç°¡å–®æ¸¬è©¦æ¡ˆä¾‹
            npx promptfoo eval \
              --config promptfoo.config.js \
              --filter "*ç°¡å–®*" \
              --output test-results/agent-consistency-simple-${{ matrix.test-env }}.json \
              --verbose
          elif [ "${{ matrix.test-suite }}" = "complex" ]; then
            # åŸ·è¡Œè¤‡é›œæ¸¬è©¦æ¡ˆä¾‹  
            npx promptfoo eval \
              --config promptfoo.config.js \
              --filter "*è¤‡é›œ*|*ä¼æ¥­ç´š*" \
              --output test-results/agent-consistency-complex-${{ matrix.test-env }}.json \
              --verbose
          else
            # åŸ·è¡Œé‚Šç•Œæ¢ä»¶æ¸¬è©¦
            npx promptfoo eval \
              --config promptfoo.config.js \
              --filter "*æ¨¡ç³Š*|*é‚Šç•Œ*|*å·¥å…·*" \
              --output test-results/agent-consistency-edge-${{ matrix.test-env }}.json \
              --verbose
          fi
          
          echo "âœ… Agentä¸€è‡´æ€§æ¸¬è©¦å®Œæˆ"
      
      - name: 'ğŸ“Š ä¸Šå‚³æ¸¬è©¦çµæœ'
        uses: actions/upload-artifact@v4
        if: always()  # å³ä½¿æ¸¬è©¦å¤±æ•—ä¹Ÿè¦ä¸Šå‚³çµæœ
        with:
          name: agent-consistency-results-${{ matrix.test-env }}-${{ matrix.test-suite }}
          path: ${{ env.WORKING_DIR }}/test-results/
          retention-days: 7

  # éšæ®µ4ï¼šæ–‡æª”ç”Ÿæˆä¸€è‡´æ€§æ¸¬è©¦
  document-consistency-tests:
    name: 'ğŸ“„ æ–‡æª”ä¸€è‡´æ€§æ¸¬è©¦'
    runs-on: ubuntu-latest
    needs: [pre-validation, setup-environment]
    if: needs.pre-validation.outputs.validation-passed == 'true'
    strategy:
      matrix:
        test-env: [test]  # æ–‡æª”æ¸¬è©¦åªåœ¨testç’°å¢ƒé‹è¡Œ
    
    steps:
      - name: 'ğŸ“¥ Checkoutä»£ç¢¼'
        uses: actions/checkout@v4
      
      - name: 'â™»ï¸ æ¢å¾©ç’°å¢ƒå¿«å–'
        uses: actions/cache@v3
        with:
          path: |
            ${{ env.WORKING_DIR }}/node_modules
            ${{ env.WORKING_DIR }}/.env
          key: ${{ runner.os }}-create-requirements-${{ matrix.test-env }}-${{ hashFiles('**/package.json') }}
      
      - name: 'ğŸ“‹ åŸ·è¡Œæ–‡æª”ç”Ÿæˆæ¸¬è©¦'
        working-directory: ${{ env.WORKING_DIR }}
        timeout-minutes: 10
        run: |
          echo "ğŸš€ é–‹å§‹åŸ·è¡Œæ–‡æª”ç”Ÿæˆä¸€è‡´æ€§æ¸¬è©¦"
          
          mkdir -p test-results
          
          # åŸ·è¡Œæ–‡æª”ä¸€è‡´æ€§æ¸¬è©¦
          npx promptfoo eval \
            --config tests/doc-generation-consistency.yml \
            --output test-results/doc-consistency-${{ matrix.test-env }}.json \
            --verbose
          
          echo "âœ… æ–‡æª”ç”Ÿæˆæ¸¬è©¦å®Œæˆ"
      
      - name: 'ğŸ“Š ä¸Šå‚³æ–‡æª”æ¸¬è©¦çµæœ'
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: doc-consistency-results-${{ matrix.test-env }}
          path: ${{ env.WORKING_DIR }}/test-results/
          retention-days: 7

  # éšæ®µ5ï¼šå·¥å…·èª¿ç”¨ä¸€è‡´æ€§æ¸¬è©¦
  tool-usage-tests:
    name: 'ğŸ”§ å·¥å…·ä½¿ç”¨æ¸¬è©¦'
    runs-on: ubuntu-latest
    needs: [pre-validation, setup-environment]
    if: needs.pre-validation.outputs.validation-passed == 'true'
    strategy:
      matrix:
        test-env: [test]
    
    steps:
      - name: 'ğŸ“¥ Checkoutä»£ç¢¼'
        uses: actions/checkout@v4
      
      - name: 'â™»ï¸ æ¢å¾©ç’°å¢ƒå¿«å–'
        uses: actions/cache@v3
        with:
          path: |
            ${{ env.WORKING_DIR }}/node_modules
            ${{ env.WORKING_DIR }}/.env
          key: ${{ runner.os }}-create-requirements-${{ matrix.test-env }}-${{ hashFiles('**/package.json') }}
      
      - name: 'ğŸ› ï¸ åŸ·è¡Œå·¥å…·ä½¿ç”¨æ¸¬è©¦'
        working-directory: ${{ env.WORKING_DIR }}
        timeout-minutes: 12
        run: |
          echo "ğŸš€ é–‹å§‹åŸ·è¡Œå·¥å…·èª¿ç”¨ä¸€è‡´æ€§æ¸¬è©¦"
          
          mkdir -p test-results
          
          npx promptfoo eval \
            --config tests/tool-usage-consistency.yml \
            --output test-results/tool-usage-${{ matrix.test-env }}.json \
            --verbose
          
          echo "âœ… å·¥å…·ä½¿ç”¨æ¸¬è©¦å®Œæˆ"
      
      - name: 'ğŸ“Š ä¸Šå‚³å·¥å…·æ¸¬è©¦çµæœ'
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: tool-usage-results-${{ matrix.test-env }}
          path: ${{ env.WORKING_DIR }}/test-results/
          retention-days: 7

  # éšæ®µ6ï¼šå“è³ªä¿è­‰æ¸¬è©¦
  quality-assurance-tests:
    name: 'âœ¨ å“è³ªä¿è­‰æ¸¬è©¦'
    runs-on: ubuntu-latest
    needs: [pre-validation, setup-environment]
    if: needs.pre-validation.outputs.validation-passed == 'true'
    strategy:
      matrix:
        test-env: [test]
    
    steps:
      - name: 'ğŸ“¥ Checkoutä»£ç¢¼'
        uses: actions/checkout@v4
      
      - name: 'â™»ï¸ æ¢å¾©ç’°å¢ƒå¿«å–'
        uses: actions/cache@v3
        with:
          path: |
            ${{ env.WORKING_DIR }}/node_modules
            ${{ env.WORKING_DIR }}/.env
          key: ${{ runner.os }}-create-requirements-${{ matrix.test-env }}-${{ hashFiles('**/package.json') }}
      
      - name: 'ğŸ† åŸ·è¡Œå“è³ªä¿è­‰æ¸¬è©¦'
        working-directory: ${{ env.WORKING_DIR }}
        timeout-minutes: 20
        run: |
          echo "ğŸš€ é–‹å§‹åŸ·è¡Œå“è³ªä¿è­‰æ¸¬è©¦"
          
          mkdir -p test-results
          
          npx promptfoo eval \
            --config tests/quality-assurance.yml \
            --output test-results/quality-assurance-${{ matrix.test-env }}.json \
            --verbose
          
          echo "âœ… å“è³ªä¿è­‰æ¸¬è©¦å®Œæˆ"
      
      - name: 'ğŸ“Š ä¸Šå‚³å“è³ªæ¸¬è©¦çµæœ'
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: quality-assurance-results-${{ matrix.test-env }}
          path: ${{ env.WORKING_DIR }}/test-results/
          retention-days: 7

  # éšæ®µ7ï¼šå“è³ªé–€æª»æª¢æŸ¥
  quality-gate-check:
    name: 'ğŸš¦ å“è³ªé–€æª»æª¢æŸ¥'
    runs-on: ubuntu-latest
    needs: [agent-consistency-tests, document-consistency-tests, tool-usage-tests, quality-assurance-tests]
    if: always()  # å³ä½¿æŸäº›æ¸¬è©¦å¤±æ•—ä¹Ÿè¦åŸ·è¡Œå“è³ªæª¢æŸ¥
    outputs:
      quality-passed: ${{ steps.quality-gate.outputs.passed }}
      overall-score: ${{ steps.quality-gate.outputs.score }}
    
    steps:
      - name: 'ğŸ“¥ Checkoutä»£ç¢¼'
        uses: actions/checkout@v4
      
      - name: 'â™»ï¸ æ¢å¾©ç’°å¢ƒå¿«å–'
        uses: actions/cache@v3
        with:
          path: |
            ${{ env.WORKING_DIR }}/node_modules
            ${{ env.WORKING_DIR }}/.env
          key: ${{ runner.os }}-create-requirements-test-${{ hashFiles('**/package.json') }}
      
      - name: 'ğŸ“¥ ä¸‹è¼‰æ‰€æœ‰æ¸¬è©¦çµæœ'
        uses: actions/download-artifact@v4
        with:
          path: ${{ env.WORKING_DIR }}/test-results/
          merge-multiple: true
      
      - name: 'ğŸ” åˆä½µæ¸¬è©¦çµæœ'
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          echo "ğŸ”„ åˆä½µæ‰€æœ‰æ¸¬è©¦çµæœ..."
          
          # å‰µå»ºåˆä½µçš„çµæœæ–‡ä»¶
          echo '{"results": {"stats": {"successes": 0, "failures": 0}, "results": []}}' > test-results/latest.json
          
          # åˆä½µæ‰€æœ‰JSONçµæœæ–‡ä»¶
          node -e "
            const fs = require('fs');
            const path = require('path');
            
            let combinedResults = {
              results: {
                stats: { successes: 0, failures: 0 },
                results: []
              }
            };
            
            // è®€å–æ‰€æœ‰çµæœæ–‡ä»¶
            const files = fs.readdirSync('test-results').filter(f => f.endsWith('.json') && f !== 'latest.json');
            
            files.forEach(file => {
              try {
                const data = JSON.parse(fs.readFileSync(path.join('test-results', file)));
                if (data.results) {
                  combinedResults.results.stats.successes += data.results.stats.successes || 0;
                  combinedResults.results.stats.failures += data.results.stats.failures || 0;
                  combinedResults.results.results = combinedResults.results.results.concat(data.results.results || []);
                }
              } catch (e) {
                console.log('è­¦å‘Šï¼šç„¡æ³•è§£ææ–‡ä»¶', file, e.message);
              }
            });
            
            fs.writeFileSync('test-results/latest.json', JSON.stringify(combinedResults, null, 2));
            console.log('âœ… æ¸¬è©¦çµæœåˆä½µå®Œæˆ');
            console.log('ç¸½æ¸¬è©¦ï¼š', combinedResults.results.stats.successes + combinedResults.results.stats.failures);
            console.log('é€šéï¼š', combinedResults.results.stats.successes);
            console.log('å¤±æ•—ï¼š', combinedResults.results.stats.failures);
          "
      
      - name: 'ğŸš¦ åŸ·è¡Œå“è³ªé–€æª»æª¢æŸ¥'
        id: quality-gate
        working-directory: ${{ env.WORKING_DIR }}
        continue-on-error: true  # å³ä½¿å“è³ªæª¢æŸ¥å¤±æ•—ä¹Ÿè¦ç”Ÿæˆå ±å‘Š
        run: |
          echo "ğŸ” é–‹å§‹å“è³ªé–€æª»æª¢æŸ¥..."
          
          # è·³éå“è³ªé–€æª»æª¢æŸ¥çš„é¸é …
          if [ "${{ inputs.skip_quality_gate }}" = "true" ]; then
            echo "âš ï¸ å“è³ªé–€æª»æª¢æŸ¥å·²è·³éï¼ˆæ‰‹å‹•è¨­å®šï¼‰"
            echo "passed=true" >> $GITHUB_OUTPUT
            echo "score=100" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # åŸ·è¡Œå“è³ªé–€æª»æª¢æŸ¥
          if node scripts/quality-gate.js; then
            echo "âœ… å“è³ªé–€æª»æª¢æŸ¥é€šé"
            echo "passed=true" >> $GITHUB_OUTPUT
            
            # æå–ç¸½åˆ†æ•¸ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if [ -f test-results/quality-report.json ]; then
              score=$(node -e "console.log(JSON.parse(require('fs').readFileSync('test-results/quality-report.json')).summary.successRate || 0)")
              echo "score=$score" >> $GITHUB_OUTPUT
            else
              echo "score=100" >> $GITHUB_OUTPUT
            fi
          else
            echo "âŒ å“è³ªé–€æª»æª¢æŸ¥å¤±æ•—"
            echo "passed=false" >> $GITHUB_OUTPUT
            
            if [ -f test-results/quality-report.json ]; then
              score=$(node -e "console.log(JSON.parse(require('fs').readFileSync('test-results/quality-report.json')).summary.successRate || 0)")
              echo "score=$score" >> $GITHUB_OUTPUT
            else
              echo "score=0" >> $GITHUB_OUTPUT
            fi
            
            exit 1
          fi
      
      - name: 'ğŸ“‹ ç”Ÿæˆå“è³ªå ±å‘Š'
        if: always()
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          echo "ğŸ“‹ ç”Ÿæˆè©³ç´°å“è³ªå ±å‘Š..."
          
          # å¦‚æœå“è³ªå ±å‘Šä¸å­˜åœ¨ï¼Œå‰µå»ºåŸºæœ¬å ±å‘Š
          if [ ! -f test-results/quality-report.md ]; then
            cat > test-results/quality-report.md << 'EOF'
          # Create Requirements Task å“è³ªå ±å‘Š
          
          ## åŸ·è¡Œæ‘˜è¦
          
          - **åŸ·è¡Œæ™‚é–“**: $(date)
          - **ç‹€æ…‹**: ${{ steps.quality-gate.outcome == 'success' && 'âœ… é€šé' || 'âŒ å¤±æ•—' }}
          - **ç¸½åˆ†**: ${{ steps.quality-gate.outputs.score }}%
          
          ## æ¸¬è©¦çµæœæ¦‚è¦½
          
          è«‹æª¢æŸ¥ä¸Šå‚³çš„artifactsä»¥ç²å–è©³ç´°æ¸¬è©¦çµæœã€‚
          EOF
          fi
          
          echo "âœ… å“è³ªå ±å‘Šç”Ÿæˆå®Œæˆ"
      
      - name: 'ğŸ“Š ä¸Šå‚³å“è³ªå ±å‘Š'
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: quality-gate-report
          path: |
            ${{ env.WORKING_DIR }}/test-results/quality-report.*
            ${{ env.WORKING_DIR }}/test-results/latest.json
          retention-days: 30
      
      - name: 'ğŸ“ æ›´æ–°PRè©•è«–'
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // å˜—è©¦è®€å–å“è³ªå ±å‘Š
            const workingDir = '${{ env.WORKING_DIR }}';
            const reportPath = path.join(workingDir, 'test-results', 'quality-report.md');
            
            let reportContent = '# Create Requirements Task å“è³ªæª¢æŸ¥çµæœ\n\n';
            
            if (fs.existsSync(reportPath)) {
              reportContent = fs.readFileSync(reportPath, 'utf8');
            } else {
              reportContent += `**ç‹€æ…‹**: ${{ steps.quality-gate.outcome == 'success' && 'âœ… é€šé' || 'âŒ éœ€è¦æ”¹é€²' }}\n`;
              reportContent += `**è©•åˆ†**: ${{ steps.quality-gate.outputs.score }}%\n\n`;
              reportContent += 'è©³ç´°å ±å‘Šè«‹æŸ¥çœ‹workflow artifactsã€‚\n';
            }
            
            // æ›´æ–°æˆ–å‰µå»ºPRè©•è«–
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const existingComment = comments.find(comment => 
              comment.body.includes('Create Requirements Task å“è³ªæª¢æŸ¥çµæœ')
            );
            
            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: reportContent
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: reportContent
              });
            }

  # éšæ®µ8ï¼šéƒ¨ç½²æ±ºç­–å’Œæ¸…ç†
  deployment-decision:
    name: 'ğŸš€ éƒ¨ç½²æ±ºç­–'
    runs-on: ubuntu-latest
    needs: [quality-gate-check]
    if: always()
    
    steps:
      - name: 'ğŸ“‹ è©•ä¼°éƒ¨ç½²æ¢ä»¶'
        run: |
          echo "ğŸ“Š å“è³ªé–€æª»æª¢æŸ¥çµæœ: ${{ needs.quality-gate-check.outputs.quality-passed }}"
          echo "ğŸ¯ æ•´é«”è©•åˆ†: ${{ needs.quality-gate-check.outputs.overall-score }}%"
          
          if [ "${{ needs.quality-gate-check.outputs.quality-passed }}" = "true" ]; then
            echo "âœ… æ‰€æœ‰å“è³ªæ¨™æº–å·²é”åˆ°ï¼ŒReady for Deployment"
            echo "ğŸ‰ Create Requirements Taské€šéæ‰€æœ‰CI/CDæª¢æŸ¥ï¼"
          else
            echo "âŒ å“è³ªæ¨™æº–æœªé”åˆ°ï¼ŒDeployment Blocked"
            echo "ğŸ”§ è«‹æ ¹æ“šå“è³ªå ±å‘Šæ”¹é€²å¾Œé‡æ–°æäº¤"
          fi
      
      - name: 'ğŸ“ˆ è¨­ç½®éƒ¨ç½²ç‹€æ…‹'
        if: needs.quality-gate-check.outputs.quality-passed == 'true'
        run: |
          echo "DEPLOYMENT_READY=true" >> $GITHUB_ENV
          echo "âœ… éƒ¨ç½²ç‹€æ…‹ï¼šReady"
      
      - name: 'ğŸ§¹ æ¸…ç†å’Œç¸½çµ'
        run: |
          echo "ğŸ Create Requirements Task CI/CD Pipeline åŸ·è¡Œå®Œæˆ"
          echo ""
          echo "ğŸ“Š åŸ·è¡Œæ‘˜è¦:"
          echo "  - è§¸ç™¼äº‹ä»¶: ${{ github.event_name }}"
          echo "  - åˆ†æ”¯: ${{ github.ref_name }}"
          echo "  - æäº¤: ${{ github.sha }}"
          echo "  - å“è³ªè©•åˆ†: ${{ needs.quality-gate-check.outputs.overall-score }}%"
          echo "  - éƒ¨ç½²ç‹€æ…‹: ${{ needs.quality-gate-check.outputs.quality-passed == 'true' && 'Ready' || 'Blocked' }}"
          echo ""
          echo "ğŸ“‹ å¾ŒçºŒæ­¥é©Ÿ:"
          if [ "${{ needs.quality-gate-check.outputs.quality-passed }}" = "true" ]; then
            echo "  1. âœ… æ‰€æœ‰æ¸¬è©¦é€šéï¼Œå¯ä»¥é€²è¡Œéƒ¨ç½²"
            echo "  2. ğŸ“„ æŸ¥çœ‹artifactsç²å–è©³ç´°å ±å‘Š"
            echo "  3. ğŸš€ ç¹¼çºŒé€²è¡Œå¾ŒçºŒé›†æˆæµç¨‹"
          else
            echo "  1. ğŸ“‹ æª¢æŸ¥å“è³ªå ±å‘Šäº†è§£å…·é«”å•é¡Œ"
            echo "  2. ğŸ”§ æ ¹æ“šå»ºè­°æ”¹é€²ä»£ç¢¼æˆ–é…ç½®"
            echo "  3. ğŸ”„ ä¿®å¾©å¾Œé‡æ–°æäº¤è§¸ç™¼æ–°çš„æª¢æŸ¥"
          fi
