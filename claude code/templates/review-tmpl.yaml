---
# Review Report Template v2
# Powered by BMAD™ Core

template:
  id: review-template-v2
  name: Review Report
  version: 2.0
  output:
    format: markdown
    filename: "docs/review/{task_id}-review.md"
    title: "Task-{task_id} Review Report: {task_name}"
    note: "Quality assessment and acceptance decision for completed task"

sections:
  - id: review-header
    title: Review Information
    instruction: |
      **Task ID:** {task_id}
      **Task Name:** {task_name}
      **Reviewer:** {agent or person name}
      **Review Date:** {date}
      **Domain:** Backend / Frontend / Database / Integration / Infrastructure
      
      Domain identification guides which scoring dimensions to apply.

  - id: acceptance-decision
    title: Acceptance Decision
    instruction: |
      **Decision:** Accept / Accept with Changes / Reject
      
      **Rationale:**
      Provide clear explanation for the decision:
      - Why this decision was made
      - Key factors influencing decision
      - Summary of critical findings
      - Overall quality assessment
      
      **CRITICAL REJECTION CRITERIA:**
      If ANY mock/stub/placeholder code is found, decision MUST be REJECT regardless of scores:
      - Examples: `// TODO: implement`, `throw new Error('Not implemented')`, mock return values
      - Rationale: Mock implementations are incomplete work and unacceptable
      
      Decision rules:
      - **Accept:** All dimensions ≥ 6.0, no critical issues, NO mock implementations
      - **Accept with Changes:** 1-2 dimensions between 5.0-5.9 with clear improvement plan, NO mock implementations
      - **Reject:** 3+ dimensions < 6.0, OR any dimension < 5.0, OR critical issues, OR ANY mock implementations found

  - id: quality-scores
    title: Quality Scores
    instruction: |
      Score dimensions based on task domain. All scores use 0.0-10.0 scale.
      
      **Scoring Levels:**
      - **Platinum (9.0-10.0):** ≥90% - Fully compliant, no issues
      - **Gold (8.0-8.9):** ≥80% - Excellent, meets high standards
      - **Silver (7.0-7.9):** ≥70% - Meets basic standards, room for improvement
      - **Bronze (6.0-6.9):** ≥60% - Barely acceptable, multiple issues
      - **Fail (<6.0):** <60% - Below standards, critical gaps
      
      **Domain-Specific Dimensions:**
      
      Select appropriate dimensions based on domain (typically 4-5 dimensions):
      
      **Backend:**
      - API Design: Endpoint design, RESTful principles, versioning
      - Security: Authentication, authorization, input validation, secrets handling
      - Error Handling: Exception handling, logging, graceful degradation
      - Testing: Test coverage, test quality, integration tests
      - Code Quality: SOLID, DRY, maintainability
      
      **Frontend:**
      - UI/UX: Design consistency, responsiveness, user flow
      - State Management: Data flow, state handling patterns
      - Performance: Load time, rendering efficiency, bundle size
      - Accessibility: WCAG compliance, keyboard navigation, screen readers
      - Testing: Component tests, user interaction tests
      
      **Database:**
      - Schema Design: Normalization, relationships, constraints
      - Indexing: Query optimization, index strategy
      - Migration: Migration quality, rollback capability
      - Performance: Query performance, data access patterns
      
      **Integration:**
      - API Integration: External API usage, error handling
      - Data Flow: Inter-service communication, data consistency
      - Error Handling: Retry logic, circuit breakers, fallbacks
      - Testing: Integration test coverage, contract tests
      
      **Infrastructure:**
      - IaC Quality: Terraform/CloudFormation quality, modularity
      - Security: IAM, network security, secrets management
      - Scalability: Auto-scaling, load balancing
      - Monitoring: Logging, metrics, alerting
      
      **Scoring Format:**
      | Dimension | Score | Comments |
      |-----------|-------|----------|
      | {dimension_1} | {score}/10.0 | {brief comment} |
      | {dimension_2} | {score}/10.0 | {brief comment} |
      | {dimension_3} | {score}/10.0 | {brief comment} |
      | {dimension_4} | {score}/10.0 | {brief comment} |
      | **Overall Score** | **{average}/10.0** | **{maturity level}** |
      
      Calculate overall score as mean of dimension scores, rounded to 1 decimal.
      State maturity level: Platinum/Gold/Silver/Bronze/Fail

  - id: test-summary
    title: Test Execution Summary
    instruction: |
      **CRITICAL: Mock Implementation Detection**
      Before reviewing tests, scan ALL implementation code for mock/stub patterns.
      If found, mark as AUTOMATIC REJECT and stop review.
      
      **All Tests Passed:** Yes / No
      
      **Test Execution Output:**
      ```
      {paste relevant test output}
      ```
      
      **Coverage:**
      - **Percentage:** {coverage}%
      - **Meets Threshold:** Yes / No (minimum 80%)
      - **Critical Paths:** All covered / Gaps identified
      
      **Test Breakdown:**
      - **Unit Tests:** {count} tests, {pass/fail}
      - **Integration Tests:** {count} tests, {pass/fail}
      - **E2E Tests:** {count} tests (if applicable), {pass/fail}
      
      **Missing Tests:**
      List any test gaps identified:
      - {missing test description}
      
      **Performance Metrics (if applicable):**
      - Response times
      - Throughput
      - Resource usage
      
      **If Tests Failed:**
      - Specific tests that failed
      - Failure reasons
      - Impact on acceptance

  - id: findings
    title: Detailed Findings
    repeatable: true
    instruction: |
      Document all issues found, organized by severity:
      
      **Finding {number}:**
      
      **Severity:** Critical / High / Medium / Low
      
      **Category:** Code Quality / Security / Performance / Testing / Documentation / Architecture
      
      **Description:** Clear description of the issue
      
      **Location:** {file_path:line_number}
      
      **Evidence:**
      ```
      {code snippet or output showing the issue}
      ```
      
      **Recommendation:** How to fix or improve
      
      **Action Required:** Must Fix / Should Fix / Nice to Have
      
      **Severity Guidelines:**
      - **Critical:** Security vulnerabilities, data loss risks, system crashes, mock implementations
      - **High:** Functional errors, major performance issues, missing critical tests
      - **Medium:** Code quality issues, minor performance problems, test coverage gaps
      - **Low:** Style issues, minor improvements, documentation gaps

  - id: alignment-verification
    title: Alignment Verification
    instruction: |
      **Requirements Fulfillment:**
      
      **Fully Satisfied:**
      - REQ-001: {how it was satisfied}
      - REQ-002: {how it was satisfied}
      
      **Partially Satisfied:**
      - REQ-003: {what's missing or incomplete}
      
      **Not Satisfied:**
      - REQ-004: {why not satisfied}
      
      **Architecture Alignment:**
      - Does implementation follow architecture design? Yes / No
      - Components used match architecture? Yes / No
      - Deviations documented? Yes / No / N/A
      - Impact: {summary of architectural alignment}
      
      **Plan Adherence:**
      - TDD cycle followed (RED → GREEN → REFACTOR)? Yes / No
      - Implementation matches plan? Yes / Partial / No
      - Deviations properly documented in dev notes? Yes / No
      - Impact: {summary of plan adherence}

  - id: risk-assessment
    title: Risk Assessment
    instruction: |
      **Risk Level:** Low / Medium / High
      
      **Rationale:**
      Explain why this risk level was assigned based on:
      - Quality scores
      - Critical findings
      - Test coverage
      - Security concerns
      - Architecture alignment
      - Mock implementations (if any, automatically High risk)
      
      **Risk Factors:**
      - {specific risk factor 1}
      - {specific risk factor 2}
      
      **Mitigation Recommendations:**
      - {recommendation 1}
      - {recommendation 2}

  - id: recommendations
    title: Recommendations
    instruction: |
      **Immediate Actions:**
      Actions required before acceptance (for Accept with Changes) or before re-review (for Reject):
      - {action 1}
      - {action 2}
      
      **Future Improvements:**
      Optional enhancements for future iterations:
      - {improvement 1}
      - {improvement 2}
      
      **Best Practices Identified:**
      Highlight any platinum-level practices worth capturing in knowledge base:
      - {practice 1}
      - {practice 2}

  - id: source-references
    title: Source References
    instruction: |
      **Plan Path:** {path to implementation plan}
      **Dev Notes Path:** {path to development notes}
      
      **Code Paths:**
      - {path to implementation file}
      - {path to implementation file}
      
      **Test Paths:**
      - {path to test file}
      - {path to test file}
