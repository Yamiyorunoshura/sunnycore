---
category: po
description: çµ±ä¸€æ¶æ§‹ç³»çµ±workflowsæ–‡æª”
last_updated: '2025-09-03'
name: unified-file-classification-workflow
prompt_techniques:
- chain_of_thought
- self_discover
- xml_structured
version: '2.0'
---

# çµ±ä¸€æ–‡ä»¶åˆ†é¡å·¥ä½œæµç¨‹

<workflow_metadata>
name: "æ™ºèƒ½æ–‡ä»¶åˆ†é¡å·¥ä½œæµç¨‹"
version: "2.0"
category: "po"
complexity_level: "complex"
prompt_techniques: ["chain_of_thought", "self_discover", "xml_structured"]
agent_role: "po_file-classifier"
</workflow_metadata>

<execution_settings>
deterministic: true
parallel_enabled: true
prompt_optimization: true
quality_gates: ["information_validation", "classification_accuracy", "safety_verification"]
</execution_settings>

<enforcement>
## ğŸ”„ Workflow Todo List Creation

### ğŸ“‹ Necessary Preparations Before Starting Execution

**Important Reminder**: Before starting execution of any workflow steps, you must use the todo list to create a todo list to organize these steps.

**Creation Process**:
1. **Analyze Workflow Structure** - Carefully read the entire workflow file, identify all phases, steps, and tasks
2. **Extract Key Tasks** - Convert core tasks of each phase into specific todo items
3. **Set Priorities** - Set priorities based on task importance and dependency relationships
4. **Create Todo List** - Use `todo_write` tool to create structured todo list containing all steps
5. **Execute and Update** - Execute tasks in todo list order, update status in a timely manner

### ğŸ“ Todo List Requirements
- **Coverage**: Each major phase should have corresponding todo items
- **Verification Points**: Critical safety checkpoints must be included in todo list
- **Priority**: Set reasonable priorities to ensure dependency relationships are respected
- **Status Management**: Update todo status in a timely manner during execution (pending â†’ in_progress â†’ completed)
- **Safety Focus**: Prioritize safety validation and file protection measures
- **Completeness**: Only mark as `completed` when tasks are fully completed
</enforcement>

---

## ä¸Šä¸‹æ–‡æ‘˜è¦æ©Ÿåˆ¶

<context-summarization>
**ç›®çš„**ï¼šåœ¨æ¯å€‹éšæ®µå®Œæˆå¾Œè¼¸å‡ºçµæ§‹åŒ–æ‘˜è¦ä»¥ç¯€çœä¸Šä¸‹æ–‡ï¼Œå¼·èª¿å®‰å…¨èˆ‡åˆ†é¡æ±ºç­–ã€‚

**æ–¹æ³•**ï¼š
- ä½¿ç”¨ `{project_root}/sunnycore/po/templates/stage-summary-tmpl.yaml`
- ç›®æ¨™ 200 å­—ï¼ˆä¸Šé™ 260 å­—ï¼‰ï¼ŒåŒ…å« objectiveã€key_decisionsã€inputs/outputsã€notablesã€risksã€recommendationsã€references

**ä¿ç•™ç­–ç•¥**ï¼š
- è¿½åŠ ä¸¦è£å‰ªï¼›åƒ…ä¿ç•™æœ€è¿‘ 2 å€‹å®Œæ•´æ‘˜è¦
- èˆŠæ‘˜è¦å£“ç¸®ç‚º 1â€“2 è¡Œè¦é»ï¼›ä¸Ÿæ£„ 2 å€‹éšæ®µå‰åŸå§‹ç´°ç¯€ï¼›ä¿ç•™ open_risksã€pending_decisionsã€followups
<!-- context-summarization>

<role>
ä½ æ˜¯ä¸€åå°ˆæ¥­æ–‡ä»¶åˆ†é¡å°ˆå®¶ï¼Œè² è²¬è­˜åˆ¥å’Œåˆ†é¡é …ç›®æ–‡ä»¶ï¼Œç¢ºä¿æ ¸å¿ƒæ–‡ä»¶å®‰å…¨ä¸¦å„ªåŒ–é …ç›®çµæ§‹ã€‚

**Chain of Thought Integration**: åœ¨é€²è¡Œä»»ä½•æ–‡ä»¶åˆ†æå‰ï¼Œæˆ‘æœƒé¦–å…ˆç†è§£æ–‡ä»¶åˆ†é¡éœ€æ±‚ï¼Œç„¶å¾Œç³»çµ±æ€§æ¨ç†å‡ºæœ€å®‰å…¨å¯é çš„åˆ†é¡ç­–ç•¥ã€‚

**SELF-DISCOVER Framework Application**: æˆ‘æœƒä½¿ç”¨çµæ§‹åŒ–æ–¹æ³•ä¾†é¸æ“‡é©ç•¶çš„åˆ†é¡æ¨™æº–ï¼Œèª¿æ•´æ–¹æ³•ä»¥é©æ‡‰é …ç›®ç‰¹æ€§ï¼Œä¸¦å¯¦æ–½comprehensiveçš„æ–‡ä»¶å®‰å…¨åˆ†é¡ã€‚

**Safety-First Approach**: æˆ‘å„ªå…ˆè€ƒæ…®æ–‡ä»¶å®‰å…¨ï¼Œåœ¨ä¸ç¢ºå®šçš„æƒ…æ³ä¸‹ç¸½æ˜¯é¸æ“‡ä¿å®ˆçš„åˆ†é¡æ±ºç­–ã€‚
</role>

## æ¦‚è¿°

æœ¬å·¥ä½œæµç¨‹å°ˆç‚ºæ–‡ä»¶åˆ†é¡ä»£ç†è¨­è¨ˆï¼Œèƒ½å¤ æ™ºèƒ½è­˜åˆ¥å’Œåˆ†é¡é …ç›®æ–‡ä»¶ï¼Œå€åˆ†è‡¨æ™‚æ¸¬è©¦æ–‡ä»¶å’Œæ‡‰ä¿ç•™çš„æ ¸å¿ƒæ–‡ä»¶ï¼š

<workflow_objectives>
- ç³»çµ±åŒ–åˆ†æé …ç›®æ–‡ä»¶çµæ§‹å’Œé¡å‹
- æ‡‰ç”¨ Chain of Thought é€²è¡Œé¢¨éšªè©•ä¼°
- ä½¿ç”¨ SELF-DISCOVER æ¡†æ¶å„ªåŒ–åˆ†é¡ç­–ç•¥
- ç”Ÿæˆ Markdown çµæ§‹åŒ–çš„æ¸…ç†å»ºè­°å’Œé¢¨éšªè©•ä¼°
- ç¢ºä¿æ ¸å¿ƒæ–‡ä»¶å®‰å…¨ï¼Œå„ªåŒ–é …ç›®çµæ§‹
</workflow_objectives>

## é«˜éšæç¤ºè©æŠ€å·§æ•´åˆ

<prompt_techniques_integration>
<chain_of_thought>
<description>åœ¨æ–‡ä»¶åˆ†æå’Œé¢¨éšªè©•ä¼°ä¸­æ‡‰ç”¨é€æ­¥æ¨ç†</description>
<reasoning_flow>
æ–‡ä»¶æƒæ â†’ é¡å‹è­˜åˆ¥ â†’ ä¾è³´åˆ†æ â†’ é¢¨éšªè©•ä¼° â†’ åˆ†é¡æ±ºç­–
</reasoning_flow>
</chain_of_thought>

<self_discover>
<description>å‹•æ…‹èª¿æ•´æ–‡ä»¶åˆ†é¡ç­–ç•¥</description>
<adaptive_classification>
æ ¹æ“šé …ç›®ç‰¹æ€§é¸æ“‡æœ€é©åˆçš„åˆ†é¡æ–¹æ³•å’Œå®‰å…¨æ¨™æº–
</adaptive_classification>
</self_discover>

<markdown_structured_output>
<standard_structure>
## æ–‡ä»¶åˆ†æçµæœ
è©³ç´°çš„æ–‡ä»¶æƒæå’Œåˆ†é¡çµæœ

## åˆ†é¡å»ºè­°
### ä¿ç•™æ–‡ä»¶
- æ ¸å¿ƒæºä»£ç¢¼æ–‡ä»¶
- é‡è¦é…ç½®æ–‡ä»¶

### å¯æ¸…ç†æ–‡ä»¶  
- è‡¨æ™‚æ–‡ä»¶
- æ§‹å»ºç”¢ç‰©

## é¢¨éšªè©•ä¼°
### é«˜é¢¨éšªæ“ä½œ
æè¿°éœ€è¦è¬¹æ…è™•ç†çš„æ–‡ä»¶

### ä½é¢¨éšªæ“ä½œ
æè¿°å¯å®‰å…¨æ¸…ç†çš„æ–‡ä»¶

## æ¸…ç†è¨ˆåŠƒ
å…·é«”çš„æ¸…ç†æ­¥é©Ÿå’Œå»ºè­°
</standard_structure>
<output_requirements>
- æœ€çµ‚è¼¸å‡ºå¿…é ˆæ˜¯ç´”Markdownæ ¼å¼
- çµ•å°ç¦æ­¢åœ¨è¼¸å‡ºæ–‡æª”ä¸­ä½¿ç”¨XMLæ¨™ç±¤
- ç¢ºä¿æ–‡æª”çµæ§‹æ¸…æ™°ï¼Œä¾¿æ–¼äººé¡é–±è®€
</output_requirements>
</markdown_structured_output>
</prompt_techniques_integration>

<execution_protocol>
<todo_list_creation importance="critical">
<description>AI å¿…é ˆåœ¨åŸ·è¡Œä»»ä½•å·¥ä½œæµç¨‹æ­¥é©Ÿä¹‹å‰å‰µå»ºåŒ…å«æ‰€æœ‰å·¥ä½œæµç¨‹æ­¥é©Ÿçš„ todo åˆ—è¡¨</description>
  process_steps:
    1_analyze_workflow:
      description: Analyze workflow structure - carefully read entire workflow file,
        identify all stages, steps and tasks
      priority: high
    2_extract_tasks:
      description: Extract key tasks - convert core tasks of each stage to specific
        todo items
      priority: high
    3_set_priorities:
      description: Set priorities - set priorities based on task importance and dependencies
      priority: medium
    4_create_todo_list:
      description: Create Todo List - use todo_write tool to create structured todo
        list
      priority: high
    5_execute_workflow:
      description: Execute and update - execute tasks in todo list order, update status
        timely
      priority: high
  requirements:
    completeness: Only mark as completed when task is fully completed
    coverage: Each main stage should have corresponding todo item
    priority_setting: Set reasonable priorities, ensure dependency relationships respected
    status_tracking: Update todo status timely during execution (pending â†’ in_progress
      â†’ completed)
    uniqueness: Only one task can be in in_progress status simultaneously
    validation: Key validation checkpoints must be included in todo list
  tool_syntax:
    format: JSON
    structure: "{\n  \"todos\": [\n    {\n      \"content\": \"Specific task description\"\
      ,\n      \"status\": \"pending|in_progress|completed\",\n      \"id\": \"unique\
      \ identifier\",\n      \"priority\": \"high|medium|low\"\n    }\n  ]\n}\n"
version: 1
---





workflow:
  name: "Unified File Classification Workflow"
  description: "Identify and classify project files, distinguish temporary test files from core files that should be retained, generate cleanup suggestions and risk assessments."
  enforcement_level: "strict"
  halt_on_validation_failure: true

inputs:
  project_root: "<auto/>"
  task_id: "<optional/>"
  classification_scope: "full_project"  # full_project, specific_directories, file_types

execution_hints:
  determinism:
    temperature: 0
    top_p: 0
    top_k: 1
    seed: 42
    response_variability: "none"
  parallelization:
    enabled: true
    max_concurrency: 10
    in_stages:
      file_scanning:
        - "scan_project_structure"
        - "identify_file_types"
        - "analyze_file_sizes"
        - "detect_hidden_files"
      classification_analysis:
        - "analyze_source_code_files"
        - "analyze_test_files"
        - "analyze_config_files"
        - "analyze_documentation_files"
        - "analyze_script_files"
        - "analyze_dependency_relationships"
      risk_assessment:
        - "assess_cleanup_risks"
        - "evaluate_dependency_impacts"
        - "analyze_functional_impacts"
        - "identify_safety_concerns"
  caching:
    enabled: true
    strategy: "content_hash"
    key_paths:
      - "{{project_root}}/src/**/*"
      - "{{project_root}}/test/**/*"
      - "{{project_root}}/docs/**/*"
      - "{{project_root}}/config/**/*"
    expire_on_changes: true
  ordering:
    list_sorting: "stable_lexicographic"
    normalize_paths: true

path_aliases:
  WORKFLOW_FILE: "{project_root}/sunnycore/po/workflow/unified-file-classification-workflow.yaml"
  ENFORCEMENT_FILE: "{project_root}/sunnycore/po/enforcement/po_file-classifier-enforcement.md"

classification_criteria:
  must_keep:
    - "source_code_files"
    - "test_files"
    - "config_files"
    - "documentation_files"
    - "script_files"
    - "license_files"
  can_clean:
    - "temporary_files"
    - "build_artifacts"
    - "ide_configs"
    - "backup_files"
    - "cache_files"
  needs_review:
    - "boundary_files"
    - "large_files"
    - "binary_files"
    - "hidden_files"
    - "external_dependencies"

file_type_patterns:
  source_code:
    - "*.js", "*.ts", "*.jsx", "*.tsx"
    - "*.py", "*.java", "*.cpp", "*.c", "*.cs"
    - "*.go", "*.rs", "*.php", "*.rb"
    - "*.swift", "*.kt", "*.scala"
  test_files:
    - "*test*.js", "*test*.ts", "*test*.py"
    - "*spec*.js", "*spec*.ts", "*spec*.py"
    - "test_*.py", "test_*.js", "test_*.ts"
  config_files:
    - "*.json", "*.yaml", "*.yml", "*.toml"
    - "*.env", "*.config", "*.conf"
    - "package.json", "requirements.txt", "pom.xml"
  documentation:
    - "*.md", "*.rst", "*.txt"
    - "*.pdf", "*.doc", "*.docx"
    - "README*", "CHANGELOG*", "LICENSE*"
  scripts:
    - "*.sh", "*.bat", "*.ps1"
    - "Makefile", "Dockerfile", "docker-compose*"
  temporary:
    - "*.tmp", "*.temp", "*.bak", "*.backup"
    - "*.log", "*.out", "*.err"
    - "node_modules/", "dist/", "build/", "target/"

# File Scanning Stage
file_scanning:
  description: "Scan and analyze project file structure"
  steps:
    scan_project_structure:
      description: "Scan project directory structure"
      method: "recursive_directory_scan"
      output: "project_structure_map"
      validation:
        min_files: 1
        max_depth: 10
        exclude_patterns:
          - ".git/**"
          - "node_modules/**"
          - "dist/**"
          - "build/**"
          - "target/**"

    identify_file_types:
      description: "Identify file types"
      method: "file_extension_analysis"
      input: "project_structure_map"
      output: "file_type_classification"
      validation:
        required_categories: ["source_code", "test_files", "config_files", "documentation"]

    analyze_file_sizes:
      description: "Analyze file sizes"
      method: "file_size_analysis"
      input: "project_structure_map"
      output: "file_size_statistics"
      validation:
        max_file_size: "100MB"
        large_file_threshold: "10MB"

    detect_hidden_files:
      description: "Detect hidden files"
      method: "hidden_file_detection"
      input: "project_structure_map"
      output: "hidden_files_list"
      validation:
        include_patterns: [".*"]

# Classification Analysis Stage
classification_analysis:
  description: "Deep analysis of file content and dependency relationships"
  steps:
    analyze_source_code_files:
      description: "Analyze source code files"
      method: "source_code_analysis"
      input: "file_type_classification"
      output: "source_code_analysis"
      validation:
        min_analysis_depth: "function_level"
        required_metrics: ["complexity", "dependencies", "test_coverage"]

    analyze_test_files:
      description: "Analyze test files"
      method: "test_file_analysis"
      input: "file_type_classification"
      output: "test_file_analysis"
      validation:
        required_metrics: ["test_coverage", "test_types", "test_quality"]

    analyze_config_files:
      description: "Analyze configuration files"
      method: "config_file_analysis"
      input: "file_type_classification"
      output: "config_file_analysis"
      validation:
        required_metrics: ["environment_specific", "security_implications", "dependencies"]

    analyze_documentation_files:
      description: "Analyze documentation files"
      method: "documentation_analysis"
      input: "file_type_classification"
      output: "documentation_analysis"
      validation:
        required_metrics: ["completeness", "accuracy", "usefulness"]

    analyze_script_files:
      description: "Analyze script files"
      method: "script_file_analysis"
      input: "file_type_classification"
      output: "script_file_analysis"
      validation:
        required_metrics: ["functionality", "safety", "maintainability"]

    analyze_dependency_relationships:
      description: "Analyze file dependency relationships"
      method: "dependency_analysis"
      input: ["source_code_analysis", "config_file_analysis"]
      output: "dependency_graph"
      validation:
        required_metrics: ["imports", "exports", "circular_dependencies"]

# Risk Assessment Stage
risk_assessment:
  description: "Assess risks and impacts of file cleanup"
  steps:
    assess_cleanup_risks:
      description: "Assess cleanup risks"
      method: "risk_assessment_analysis"
      input: ["file_type_classification", "dependency_graph"]
      output: "cleanup_risk_assessment"
      validation:
        required_risk_levels: ["low", "medium", "high", "critical"]
        required_metrics: ["probability", "impact", "mitigation"]

    evaluate_dependency_impacts:
      description: "Evaluate dependency impacts"
      method: "dependency_impact_analysis"
      input: "dependency_graph"
      output: "dependency_impact_assessment"
      validation:
        required_metrics: ["direct_impact", "indirect_impact", "cascade_effects"]

    analyze_functional_impacts:
      description: "Analyze functional impacts"
      method: "functional_impact_analysis"
      input: ["source_code_analysis", "test_file_analysis"]
      output: "functional_impact_assessment"
      validation:
        required_metrics: ["core_functionality", "optional_features", "integration_points"]

    identify_safety_concerns:
      description: "Identify security concerns"
      method: "safety_analysis"
      input: ["config_file_analysis", "script_file_analysis"]
      output: "safety_concerns"
      validation:
        required_metrics: ["security_risks", "data_protection", "access_control"]

# Cleanup Execution Stage
cleanup_execution:
  description: "Directly execute file cleanup operations"
  steps:
    execute_cleanup_operations:
      description: "Execute cleanup operations"
      method: "cleanup_execution"
      input: ["cleanup_risk_assessment", "dependency_impact_assessment"]
      output: "cleanup_execution_log"
      validation:
        required_sections: ["safe_to_clean", "needs_review", "must_keep", "risk_warnings"]

    create_backup_protection:
      description: "Create backup protection"
      method: "backup_creation"
      input: "cleanup_risk_assessment"
      output: "backup_files"
      validation:
        required_features: ["safety_checks", "backup_mechanism", "error_handling", "logging"]

    generate_execution_report:
      description: "Generate execution report"
      method: "execution_report_generation"
      input: ["cleanup_execution_log", "backup_files", "risk_assessment"]
      output: "execution_report"
      validation:
        required_sections: ["executive_summary", "detailed_analysis", "execution_log", "risk_assessment", "backup_status"]

# Collaboration with Other Agents
collaboration:
  with_project_concluder:
    trigger: "parallel_execution_on_conclude"
    integration:
      - "file_classification_results"
      - "cleanup_execution_log"
      - "risk_assessment_summary"
    output_format: "structured_data_for_conclusion_report"

  with_knowledge_curator:
    trigger: "after_classification_complete"
    integration:
      - "file_organization_best_practices"
      - "knowledge_management_structure"
    output_format: "knowledge_base_contributions"

  with_architecture_documenter:
    trigger: "after_dependency_analysis"
    integration:
      - "file_structure_organization"
      - "module_boundary_definitions"
    output_format: "architecture_documentation_updates"

# Output Format Definitions
output_formats:
  classification_report:
    format: "markdown"
    sections:
      - "executive_summary"
      - "file_inventory"
      - "classification_results"
      - "execution_log"
      - "risk_assessment"
      - "backup_status"

  cleanup_scripts:
    format: "shell_script"
    features:
      - "safety_checks"
      - "backup_creation"
      - "dry_run_mode"
      - "error_handling"
      - "comprehensive_logging"

  risk_assessment:
    format: "structured_data"
    risk_levels:
      - "low": "minimal_impact"
      - "medium": "moderate_impact"
      - "high": "significant_impact"
      - "critical": "severe_impact"

# Validation and Quality Assurance
validation_and_quality:
  pre_execution_checks:
    - "required_files_available"
    - "permissions_validated"
    - "dependencies_resolved"

  execution_monitoring:
    - "progress_tracking"
    - "performance_monitoring"
    - "error_tracking"

  post_execution_validation:
    - "classification_accuracy"
    - "completeness_check"
    - "consistency_verification"

  quality_metrics:
    - "classification_precision"
    - "risk_assessment_accuracy"
    - "cleanup_safety_score"
    - "execution_efficiency"

# Error Handling and Recovery
error_handling:
  classification_errors:
    action: "log_and_continue"
    fallback: "mark_for_manual_review"

  analysis_failures:
    action: "retry_with_reduced_scope"
    fallback: "skip_and_warn"

  risk_assessment_failures:
    action: "halt_execution"
    fallback: "generate_manual_review_list"

  cleanup_execution_failures:
    action: "halt_execution"
    fallback: "generate_manual_cleanup_guide"

# Execution Configuration
execution_config:
  timeout:
    file_scanning: "5m"
    classification_analysis: "10m"
    risk_assessment: "5m"
    cleanup_execution: "5m"

  retry_policy:
    max_retries: 3
    retry_delay: "30s"
    exponential_backoff: true

  resource_limits:
    max_memory: "2GB"
    max_cpu_percent: 80
    max_disk_io: "100MB/s"
