---
template: unified-file-classification-workflow
version: 1

# üîÑ Workflow Todo List Creation Process
todo_list_creation:
  description: "AI must create todo list containing all workflow steps before executing any workflow steps"
  importance: "critical"

  # üõ†Ô∏è Todo List Tool Usage Guide
  tool_syntax:
    format: "JSON"
    structure: |
      {
        "todos": [
          {
            "content": "Specific task description",
            "status": "pending|in_progress|completed",
            "id": "unique identifier",
            "priority": "high|medium|low"
          }
        ]
      }

  process_steps:
    1_analyze_workflow:
      description: "Analyze workflow structure - carefully read entire workflow file, identify all stages, steps and tasks"
      priority: "high"

    2_extract_tasks:
      description: "Extract key tasks - convert core tasks of each stage to specific todo items"
      priority: "high"

    3_set_priorities:
      description: "Set priorities - set priorities based on task importance and dependencies"
      priority: "medium"

    4_create_todo_list:
      description: "Create Todo List - use todo_write tool to create structured todo list"
      priority: "high"

    5_execute_workflow:
      description: "Execute and update - execute tasks in todo list order, update status timely"
      priority: "high"

  # üìù Todo List Requirements
  requirements:
    coverage: "Each main stage should have corresponding todo item"
    validation: "Key validation checkpoints must be included in todo list"
    priority_setting: "Set reasonable priorities, ensure dependency relationships respected"
    status_tracking: "Update todo status timely during execution (pending ‚Üí in_progress ‚Üí completed)"
    uniqueness: "Only one task can be in in_progress status simultaneously"
    completeness: "Only mark as completed when task is fully completed"

# Separator line, following is original workflow content
---

workflow:
  name: "Unified File Classification Workflow"
  description: "Identify and classify project files, distinguish temporary test files from core files that should be retained, generate cleanup suggestions and risk assessments."
  enforcement_level: "strict"
  halt_on_validation_failure: true

inputs:
  project_root: "<auto>"
  task_id: "<optional>"
  classification_scope: "full_project"  # full_project, specific_directories, file_types

execution_hints:
  determinism:
    temperature: 0
    top_p: 0
    top_k: 1
    seed: 42
    response_variability: "none"
  parallelization:
    enabled: true
    max_concurrency: 10
    in_stages:
      file_scanning:
        - "scan_project_structure"
        - "identify_file_types"
        - "analyze_file_sizes"
        - "detect_hidden_files"
      classification_analysis:
        - "analyze_source_code_files"
        - "analyze_test_files"
        - "analyze_config_files"
        - "analyze_documentation_files"
        - "analyze_script_files"
        - "analyze_dependency_relationships"
      risk_assessment:
        - "assess_cleanup_risks"
        - "evaluate_dependency_impacts"
        - "analyze_functional_impacts"
        - "identify_safety_concerns"
  caching:
    enabled: true
    strategy: "content_hash"
    key_paths:
      - "{{project_root}}/src/**/*"
      - "{{project_root}}/test/**/*"
      - "{{project_root}}/docs/**/*"
      - "{{project_root}}/config/**/*"
    expire_on_changes: true
  ordering:
    list_sorting: "stable_lexicographic"
    normalize_paths: true

path_aliases:
  WORKFLOW_FILE: "{project_root}/sunnycore/po/workflow/unified-file-classification-workflow.yaml"
  ENFORCEMENT_FILE: "{project_root}/sunnycore/po/enforcement/file-classifier-enforcement.md"

classification_criteria:
  must_keep:
    - "source_code_files"
    - "test_files"
    - "config_files"
    - "documentation_files"
    - "script_files"
    - "license_files"
  can_clean:
    - "temporary_files"
    - "build_artifacts"
    - "ide_configs"
    - "backup_files"
    - "cache_files"
  needs_review:
    - "boundary_files"
    - "large_files"
    - "binary_files"
    - "hidden_files"
    - "external_dependencies"

file_type_patterns:
  source_code:
    - "*.js", "*.ts", "*.jsx", "*.tsx"
    - "*.py", "*.java", "*.cpp", "*.c", "*.cs"
    - "*.go", "*.rs", "*.php", "*.rb"
    - "*.swift", "*.kt", "*.scala"
  test_files:
    - "*test*.js", "*test*.ts", "*test*.py"
    - "*spec*.js", "*spec*.ts", "*spec*.py"
    - "test_*.py", "test_*.js", "test_*.ts"
  config_files:
    - "*.json", "*.yaml", "*.yml", "*.toml"
    - "*.env", "*.config", "*.conf"
    - "package.json", "requirements.txt", "pom.xml"
  documentation:
    - "*.md", "*.rst", "*.txt"
    - "*.pdf", "*.doc", "*.docx"
    - "README*", "CHANGELOG*", "LICENSE*"
  scripts:
    - "*.sh", "*.bat", "*.ps1"
    - "Makefile", "Dockerfile", "docker-compose*"
  temporary:
    - "*.tmp", "*.temp", "*.bak", "*.backup"
    - "*.log", "*.out", "*.err"
    - "node_modules/", "dist/", "build/", "target/"

# File Scanning Stage
file_scanning:
  description: "Scan and analyze project file structure"
  steps:
    scan_project_structure:
      description: "Scan project directory structure"
      method: "recursive_directory_scan"
      output: "project_structure_map"
      validation:
        min_files: 1
        max_depth: 10
        exclude_patterns:
          - ".git/**"
          - "node_modules/**"
          - "dist/**"
          - "build/**"
          - "target/**"

    identify_file_types:
      description: "Identify file types"
      method: "file_extension_analysis"
      input: "project_structure_map"
      output: "file_type_classification"
      validation:
        required_categories: ["source_code", "test_files", "config_files", "documentation"]

    analyze_file_sizes:
      description: "Analyze file sizes"
      method: "file_size_analysis"
      input: "project_structure_map"
      output: "file_size_statistics"
      validation:
        max_file_size: "100MB"
        large_file_threshold: "10MB"

    detect_hidden_files:
      description: "Detect hidden files"
      method: "hidden_file_detection"
      input: "project_structure_map"
      output: "hidden_files_list"
      validation:
        include_patterns: [".*"]

# Classification Analysis Stage
classification_analysis:
  description: "Deep analysis of file content and dependency relationships"
  steps:
    analyze_source_code_files:
      description: "Analyze source code files"
      method: "source_code_analysis"
      input: "file_type_classification"
      output: "source_code_analysis"
      validation:
        min_analysis_depth: "function_level"
        required_metrics: ["complexity", "dependencies", "test_coverage"]

    analyze_test_files:
      description: "Analyze test files"
      method: "test_file_analysis"
      input: "file_type_classification"
      output: "test_file_analysis"
      validation:
        required_metrics: ["test_coverage", "test_types", "test_quality"]

    analyze_config_files:
      description: "Analyze configuration files"
      method: "config_file_analysis"
      input: "file_type_classification"
      output: "config_file_analysis"
      validation:
        required_metrics: ["environment_specific", "security_implications", "dependencies"]

    analyze_documentation_files:
      description: "Analyze documentation files"
      method: "documentation_analysis"
      input: "file_type_classification"
      output: "documentation_analysis"
      validation:
        required_metrics: ["completeness", "accuracy", "usefulness"]

    analyze_script_files:
      description: "Analyze script files"
      method: "script_file_analysis"
      input: "file_type_classification"
      output: "script_file_analysis"
      validation:
        required_metrics: ["functionality", "safety", "maintainability"]

    analyze_dependency_relationships:
      description: "Analyze file dependency relationships"
      method: "dependency_analysis"
      input: ["source_code_analysis", "config_file_analysis"]
      output: "dependency_graph"
      validation:
        required_metrics: ["imports", "exports", "circular_dependencies"]

# Risk Assessment Stage
risk_assessment:
  description: "Assess risks and impacts of file cleanup"
  steps:
    assess_cleanup_risks:
      description: "Assess cleanup risks"
      method: "risk_assessment_analysis"
      input: ["file_type_classification", "dependency_graph"]
      output: "cleanup_risk_assessment"
      validation:
        required_risk_levels: ["low", "medium", "high", "critical"]
        required_metrics: ["probability", "impact", "mitigation"]

    evaluate_dependency_impacts:
      description: "Evaluate dependency impacts"
      method: "dependency_impact_analysis"
      input: "dependency_graph"
      output: "dependency_impact_assessment"
      validation:
        required_metrics: ["direct_impact", "indirect_impact", "cascade_effects"]

    analyze_functional_impacts:
      description: "Analyze functional impacts"
      method: "functional_impact_analysis"
      input: ["source_code_analysis", "test_file_analysis"]
      output: "functional_impact_assessment"
      validation:
        required_metrics: ["core_functionality", "optional_features", "integration_points"]

    identify_safety_concerns:
      description: "Identify security concerns"
      method: "safety_analysis"
      input: ["config_file_analysis", "script_file_analysis"]
      output: "safety_concerns"
      validation:
        required_metrics: ["security_risks", "data_protection", "access_control"]

# Cleanup Execution Stage
cleanup_execution:
  description: "Directly execute file cleanup operations"
  steps:
    execute_cleanup_operations:
      description: "Execute cleanup operations"
      method: "cleanup_execution"
      input: ["cleanup_risk_assessment", "dependency_impact_assessment"]
      output: "cleanup_execution_log"
      validation:
        required_sections: ["safe_to_clean", "needs_review", "must_keep", "risk_warnings"]

    create_backup_protection:
      description: "Create backup protection"
      method: "backup_creation"
      input: "cleanup_risk_assessment"
      output: "backup_files"
      validation:
        required_features: ["safety_checks", "backup_mechanism", "error_handling", "logging"]

    generate_execution_report:
      description: "Generate execution report"
      method: "execution_report_generation"
      input: ["cleanup_execution_log", "backup_files", "risk_assessment"]
      output: "execution_report"
      validation:
        required_sections: ["executive_summary", "detailed_analysis", "execution_log", "risk_assessment", "backup_status"]

# Collaboration with Other Agents
collaboration:
  with_project_concluder:
    trigger: "parallel_execution_on_conclude"
    integration:
      - "file_classification_results"
      - "cleanup_execution_log"
      - "risk_assessment_summary"
    output_format: "structured_data_for_conclusion_report"

  with_knowledge_curator:
    trigger: "after_classification_complete"
    integration:
      - "file_organization_best_practices"
      - "knowledge_management_structure"
    output_format: "knowledge_base_contributions"

  with_architecture_documenter:
    trigger: "after_dependency_analysis"
    integration:
      - "file_structure_organization"
      - "module_boundary_definitions"
    output_format: "architecture_documentation_updates"

# Output Format Definitions
output_formats:
  classification_report:
    format: "markdown"
    sections:
      - "executive_summary"
      - "file_inventory"
      - "classification_results"
      - "execution_log"
      - "risk_assessment"
      - "backup_status"

  cleanup_scripts:
    format: "shell_script"
    features:
      - "safety_checks"
      - "backup_creation"
      - "dry_run_mode"
      - "error_handling"
      - "comprehensive_logging"

  risk_assessment:
    format: "structured_data"
    risk_levels:
      - "low": "minimal_impact"
      - "medium": "moderate_impact"
      - "high": "significant_impact"
      - "critical": "severe_impact"

# Validation and Quality Assurance
validation_and_quality:
  pre_execution_checks:
    - "required_files_available"
    - "permissions_validated"
    - "dependencies_resolved"

  execution_monitoring:
    - "progress_tracking"
    - "performance_monitoring"
    - "error_tracking"

  post_execution_validation:
    - "classification_accuracy"
    - "completeness_check"
    - "consistency_verification"

  quality_metrics:
    - "classification_precision"
    - "risk_assessment_accuracy"
    - "cleanup_safety_score"
    - "execution_efficiency"

# Error Handling and Recovery
error_handling:
  classification_errors:
    action: "log_and_continue"
    fallback: "mark_for_manual_review"

  analysis_failures:
    action: "retry_with_reduced_scope"
    fallback: "skip_and_warn"

  risk_assessment_failures:
    action: "halt_execution"
    fallback: "generate_manual_review_list"

  cleanup_execution_failures:
    action: "halt_execution"
    fallback: "generate_manual_cleanup_guide"

# Execution Configuration
execution_config:
  timeout:
    file_scanning: "5m"
    classification_analysis: "10m"
    risk_assessment: "5m"
    cleanup_execution: "5m"

  retry_policy:
    max_retries: 3
    retry_delay: "30s"
    exponential_backoff: true

  resource_limits:
    max_memory: "2GB"
    max_cpu_percent: 80
    max_disk_io: "100MB/s"
